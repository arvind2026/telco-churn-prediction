{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customer Churn Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Notebook Output is Working\n"
     ]
    }
   ],
   "source": [
    "# Core Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, \n",
    "    confusion_matrix, classification_report, roc_curve\n",
    ")\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✅ Notebook Output is Working\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score \n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, fbeta_score\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import feature_selection\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, precision_recall_curve\n",
    "from sklearn.metrics import auc, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import make_scorer, recall_score, log_loss\n",
    "from sklearn.metrics import average_precision_score\n",
    "#Standard libraries for data visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno\n",
    "msno.matrix(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop([\"customerID\"], axis = 1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"TotalCharges\"] == ' ']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['TotalCharges'] = pd.to_numeric(data.TotalCharges, errors='coerce')\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are 11 records with missing Total charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"tenure\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(labels=data[data[\"tenure\"] == 0].index, axis = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.fillna(data[\"TotalCharges\"].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['TotalCharges'] = pd.to_numeric(data.TotalCharges, errors='coerce')\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.SeniorCitizen.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.SeniorCitizen = data.SeniorCitizen.map({0: \"No\", 1: \"Yes\"})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.InternetService.describe(include=[\"object\", \"bool\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_ = [\"No\", \"yes\"]\n",
    "fig = make_subplots(rows=1, cols=1)\n",
    "\n",
    "fig.add_trace(go.Pie(labels=type_, values=data['Churn'].value_counts(), name=\"Churn\"))\n",
    "\n",
    "# Use `hole` to create a donut-like pie chart\n",
    "fig.update_traces(hole=.4, hoverinfo=\"label+percent+name\", textfont_size=16)\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text=\"Churn Distributions\",\n",
    "    # Add annotations in the center of the donut pies.\n",
    "    annotations=[dict(text='Churn', x=0.5, y=0.5, font_size=20, showarrow=False)])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Churn[data.Churn == \"No\"].groupby(by = data.gender).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Churn[data.Churn == \"Yes\"].groupby(by = data.gender).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "labels =[\"Churn: Yes\",\"Churn:No\"]\n",
    "values = [1869,5163]\n",
    "labels_gender = [\"F\",\"M\",\"F\",\"M\"]\n",
    "sizes_gender = [939,930 , 2544,2619]\n",
    "colors = ['#ff6666', '#66b3ff']\n",
    "colors_gender = ['#c2c2f0','#ffb3e6', '#c2c2f0','#ffb3e6']\n",
    "explode = (0.3,0.3) \n",
    "explode_gender = (0.1,0.1,0.1,0.1)\n",
    "textprops = {\"fontsize\":15}\n",
    "#Plot\n",
    "plt.pie(values, labels=labels,autopct='%1.1f%%',pctdistance=1.08, labeldistance=0.8,colors=colors, startangle=90,frame=True, explode=explode,radius=10, textprops =textprops, counterclock = True, )\n",
    "plt.pie(sizes_gender,labels=labels_gender,colors=colors_gender,startangle=90, explode=explode_gender,radius=7, textprops =textprops, counterclock = True, )\n",
    "#Draw circle\n",
    "centre_circle = plt.Circle((0,0),5,color='black', fc='white',linewidth=0)\n",
    "fig = plt.gcf()\n",
    "fig.gca().add_artist(centre_circle)\n",
    "\n",
    "plt.title('Churn Distribution w.r.t Gender: Male(M), Female(F)', fontsize=15, y=1.1)\n",
    "\n",
    "# show plot \n",
    " \n",
    "plt.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(data, x=\"Churn\", color = \"Contract\", barmode = \"group\", title = \"<b>Customer contract distribution<b>\")\n",
    "fig.update_layout(width=700, height=500, bargap=0.2)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Customers with monthly contract are more likely to churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data['PaymentMethod'].unique()\n",
    "values = data['PaymentMethod'].value_counts()\n",
    "\n",
    "fig = go.Figure(data=[go.Pie(labels=labels, values=values, hole=.3)])\n",
    "fig.update_layout(title_text=\"<b>Payment Method Distribution</b>\")\n",
    "fig.show()\n",
    "\n",
    "fig = px.histogram(data, x=\"Churn\", color=\"PaymentMethod\", title=\"<b>Customer Payment Method distribution w.r.t. Churn</b>\")\n",
    "fig.update_layout(width=700, height=500, bargap=0.1)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"gender\"]==\"Male\"][[\"InternetService\", \"Churn\"]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"gender\"]==\"Female\"][[\"InternetService\", \"Churn\"]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "  x = [['Churn:No', 'Churn:No', 'Churn:Yes', 'Churn:Yes'],\n",
    "       [\"Female\", \"Male\", \"Female\", \"Male\"]],\n",
    "  y = [965, 992, 219, 240],\n",
    "  name = 'DSL',\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "  x = [['Churn:No', 'Churn:No', 'Churn:Yes', 'Churn:Yes'],\n",
    "       [\"Female\", \"Male\", \"Female\", \"Male\"]],\n",
    "  y = [889, 910, 664, 633],\n",
    "  name = 'Fiber optic',\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "  x = [['Churn:No', 'Churn:No', 'Churn:Yes', 'Churn:Yes'],\n",
    "       [\"Female\", \"Male\", \"Female\", \"Male\"]],\n",
    "  y = [690, 717, 56, 57],\n",
    "  name = 'No Internet',\n",
    "))\n",
    "\n",
    "fig.update_layout(title_text=\"<b>Churn Distribution w.r.t. Internet Service and Gender</b>\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = {\"Yes\": \"#FF97FF\", \"No\": \"#AB63FA\"}\n",
    "fig = px.histogram(data, x=\"Churn\", color=\"Dependents\", barmode=\"group\", title=\"<b>Dependents distribution</b>\", color_discrete_map=color_map)\n",
    "fig.update_layout(width=700, height=500, bargap=0.1)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = {\"Yes\": '#FFA15A', \"No\": '#00CC96'}\n",
    "fig = px.histogram(data, x=\"Churn\", color=\"Partner\", barmode=\"group\", title=\"<b>Chrun distribution w.r.t. Partners</b>\", color_discrete_map=color_map)\n",
    "fig.update_layout(width=700, height=500, bargap=0.1)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = {\"Yes\": '#00CC96', \"No\": '#B6E880'}\n",
    "fig = px.histogram(data, x=\"Churn\", color=\"SeniorCitizen\", title=\"<b>Chrun distribution w.r.t. Senior Citizen</b>\", color_discrete_map=color_map)\n",
    "fig.update_layout(width=700, height=500, bargap=0.1)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = {\"Yes\": \"#FF97FF\", \"No\": \"#AB63FA\"}\n",
    "fig = px.histogram(data, x=\"Churn\", color=\"OnlineSecurity\", barmode=\"group\", title=\"<b>Churn w.r.t Online Security</b>\", color_discrete_map=color_map)\n",
    "fig.update_layout(width=700, height=500, bargap=0.1)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = {\"Yes\": '#FFA15A', \"No\": '#00CC96'}\n",
    "fig = px.histogram(data, x=\"Churn\", color=\"PaperlessBilling\",  title=\"<b>Chrun distribution w.r.t. Paperless Billing</b>\", color_discrete_map=color_map)\n",
    "fig.update_layout(width=700, height=500, bargap=0.1)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(data, x=\"Churn\", color=\"TechSupport\",barmode=\"group\",  title=\"<b>Chrun distribution w.r.t. TechSupport</b>\")\n",
    "fig.update_layout(width=700, height=500, bargap=0.1)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = {\"Yes\": '#00CC96', \"No\": '#B6E880'}\n",
    "fig = px.histogram(data, x=\"Churn\", color=\"PhoneService\", title=\"<b>Chrun distribution w.r.t. Phone Service</b>\", color_discrete_map=color_map)\n",
    "fig.update_layout(width=700, height=500, bargap=0.1)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"paper\",font_scale=1.1)\n",
    "ax = sns.kdeplot(data.MonthlyCharges[(data[\"Churn\"] == 'No') ],\n",
    "                color=\"Red\", shade = True);\n",
    "ax = sns.kdeplot(data.MonthlyCharges[(data[\"Churn\"] == 'Yes') ],\n",
    "                ax =ax, color=\"Blue\", shade= True);\n",
    "ax.legend([\"Not Churn\",\"Churn\"],loc='upper right');\n",
    "ax.set_ylabel('Density');\n",
    "ax.set_xlabel('Monthly Charges');\n",
    "ax.set_title('Distribution of monthly charges by churn');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customers with higher monthly charges are more likely to churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.kdeplot(data.TotalCharges[(data[\"Churn\"] == 'No') ],\n",
    "                color=\"Gold\", shade = True);\n",
    "ax = sns.kdeplot(data.TotalCharges[(data[\"Churn\"] == 'Yes') ],\n",
    "                ax =ax, color=\"Green\", shade= True);\n",
    "ax.legend([\"Not Chuurn\",\"Churn\"],loc='upper right');\n",
    "ax.set_ylabel('Density');\n",
    "ax.set_xlabel('Total Charges');\n",
    "ax.set_title('Distribution of total charges by churn');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(data, x='Churn', y = 'tenure')\n",
    "\n",
    "# Update yaxis properties\n",
    "fig.update_yaxes(title_text='Tenure (Months)', row=1, col=1)\n",
    "# Update xaxis properties\n",
    "fig.update_xaxes(title_text='Churn', row=1, col=1)\n",
    "\n",
    "# Update size and title\n",
    "fig.update_layout(autosize=True, width=750, height=600,\n",
    "    title_font=dict(size=25, family='Courier'),\n",
    "    title='<b>Tenure vs Churn</b>',\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New customers are more likely to churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a label encoder object\n",
    "le = LabelEncoder()\n",
    "# Label Encoding will be used for columns with 2 or less unique \n",
    "values\n",
    "le_count = 0\n",
    "for col in data.columns[1:]:\n",
    "    if data[col].dtype == 'object':\n",
    "        if len(list(data[col].unique())) <= 2:\n",
    "            le.fit(data[col])\n",
    "            data[col] = le.transform(data[col])\n",
    "            le_count += 1\n",
    "print('{} columns were label encoded.'.format(le_count))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data[['SeniorCitizen', 'Partner', 'Dependents',\n",
    "       'tenure', 'PhoneService', 'PaperlessBilling',\n",
    "        'MonthlyCharges', 'TotalCharges']]\n",
    "\n",
    "correlations = data2.corrwith(data.Churn)\n",
    "correlations = correlations[correlations!=1]\n",
    "positive_correlations = correlations[correlations >0].sort_values(ascending = False)\n",
    "negative_correlations =correlations[correlations<0].sort_values(ascending = False)\n",
    "\n",
    "correlations.plot.bar(\n",
    "        figsize = (18, 10), \n",
    "        fontsize = 15, \n",
    "        color = 'grey',\n",
    "        rot = 45, grid = True)\n",
    "plt.title('Correlation with Churn Rate \\n',\n",
    "horizontalalignment=\"center\", fontstyle = \"normal\", \n",
    "fontsize = \"22\", fontfamily = \"sans-serif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set and compute the Correlation Matrix:\n",
    "sns.set(style=\"white\")\n",
    "plt.figure(figsize=(18, 15))\n",
    "\n",
    "corr = data.apply(lambda x: pd.factorize(x)[0]).corr()\n",
    "\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "ax = sns.heatmap(corr, mask=mask, xticklabels=corr.columns, yticklabels=corr.columns, annot=True, linewidths=.2, cmap='coolwarm', vmin=0.3, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set and compute the Correlation Matrix:\n",
    "sns.set(style=\"white\")\n",
    "corr = data2.corr()\n",
    "\n",
    "#Generate a mask for the upper triangle:\n",
    "\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "#Set up the matplotlib figure and a diverging colormap:\n",
    "f, ax = plt.subplots(figsize=(18, 15))\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "#Draw the heatmap with the mask and correct aspect ratio:\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,square=True,annot = True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multicollinearity check using VIF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TODO:\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "data_ = pd.read_csv(\"data.csv\")\n",
    "X = data_[['gender', 'SeniorCitizen', 'Partner', 'Dependents','tenure', 'PhoneService','PaperlessBilling','MonthlyCharges','TotalCharges']]\n",
    "\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = X.columns\n",
    "  \n",
    "#calculating VIF for each feature\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i)\n",
    "                          for i in range(len(X.columns))]\n",
    "  \n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(dataframe):\n",
    "    if dataframe.dtype == \"object\":\n",
    "        dataframe = LabelEncoder().fit_transform(dataframe)\n",
    "    return dataframe\n",
    "\n",
    "data = data.apply(lambda x: encode_data(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns = \"Churn\")\n",
    "y = data[\"Churn\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 4, stratify =y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distplot(feature, frame, color='r'):\n",
    "    plt.figure(figsize=(8,3))\n",
    "    plt.title(\"Distribution for {}\".format(feature))\n",
    "    ax = sns.distplot(frame[feature], color= color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col =  [\"tenure\", 'MonthlyCharges', 'TotalCharges']\n",
    "for features in col :distplot(features, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features need standard scaling as all of them are distributed over different range values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_std = pd.DataFrame(StandardScaler().fit_transform(data[col]).astype('float64'), columns = col)\n",
    "for feat in col: distplot(feat, data_std, color='c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data.columns:\n",
    "    print(i, \": \", data_[i].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the columns into 3 categories, one ofor standardisation, one for label encoding and one for one hot encoding\n",
    "\n",
    "cat_cols_ohe =['PaymentMethod', 'Contract', 'InternetService'] # those that need one-hot encoding\n",
    "cat_cols_le = list(set(X_train.columns)- set(col) - set(cat_cols_ohe)) #those that need label encoding\n",
    "\n",
    "print(cat_cols_le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train[col] = StandardScaler().fit_transform(X_train[col])\n",
    "X_test[col] = StandardScaler().fit_transform(X_test[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "models.append(('Logistic Regression', LogisticRegression(solver='liblinear', random_state = 0, class_weight='balanced')))\n",
    "models.append(('SVC', SVC(kernel = 'linear', random_state = 0)))\n",
    "models.append(('Kernel SVM', SVC(kernel = 'rbf', random_state = 0)))\n",
    "models.append(('KNN', KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)))\n",
    "models.append(('Gaussian NB', GaussianNB()))\n",
    "models.append(('Decision Tree Classifier', DecisionTreeClassifier(criterion = 'entropy', random_state = 0)))\n",
    "models.append(('Random Forest', RandomForestClassifier(n_estimators=100, criterion = 'entropy', random_state = 0)))\n",
    "models.append((\"Adaboost\", AdaBoostClassifier()))\n",
    "models.append((\"Gradient boost classifier\", GradientBoostingClassifier()))\n",
    "models.append((\"Voting Classifier\",  VotingClassifier(estimators=[('gbc', GradientBoostingClassifier()), ('lr', LogisticRegression()), ('abc',  AdaBoostClassifier())], voting='soft')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_results =[]\n",
    "auc_results =[]\n",
    "names = []\n",
    "\n",
    "result_col = [\"Algorithm\", \"ROC AUC Mean\", \"ROC AUC STD\", \"Accuracy Mean\", \"Accuracy STD\"]\n",
    "model_results = pd.DataFrame(columns = result_col)\n",
    "\n",
    "i=0\n",
    "# K- fold cross validation\n",
    "\n",
    "for name, model in models:\n",
    "    names.append(name)\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=0)\n",
    "    \n",
    "    cv_acc_results = model_selection.cross_val_score(model, X_train, y_train, \n",
    "                    cv = kfold, scoring=\"accuracy\")\n",
    "    cv_auc_results = model_selection.cross_val_score(model, X_train, y_train,\n",
    "                    cv = kfold, scoring=\"roc_auc\")\n",
    "    acc_results.append(cv_acc_results)\n",
    "    auc_results.append(cv_auc_results)\n",
    "    \n",
    "    model_results.loc[i] = [name, \n",
    "                           round(cv_auc_results.mean()*100,2),\n",
    "                           round(cv_auc_results.std()*100,2),\n",
    "                           round(cv_acc_results.mean()*100,2),\n",
    "                           round(cv_acc_results.std()*100,2)]\n",
    "    i+=1\n",
    "\n",
    "model_results.sort_values(by = ['ROC AUC Mean'], ascending=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25,15))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(acc_results)\n",
    "ax.set_xticklabels(names)\n",
    "\n",
    "plt.ylabel('ROC AUC Score\\n',\n",
    "horizontalalignment=\"center\",fontstyle = \"normal\", \n",
    "fontsize = \"large\", fontfamily = \"sans-serif\")\n",
    "\n",
    "plt.xlabel('\\n Baseline Classification Algorithms\\n',\n",
    "horizontalalignment=\"center\",fontstyle = \"normal\", \n",
    "fontsize = \"large\", fontfamily = \"sans-serif\")\n",
    "\n",
    "plt.title('Accuracy Score Comparison \\n',\n",
    "horizontalalignment=\"center\", fontstyle = \"normal\", \n",
    "fontsize = \"22\", fontfamily = \"sans-serif\")\n",
    "\n",
    "plt.xticks(rotation=0, horizontalalignment=\"center\")\n",
    "plt.yticks(rotation=0, horizontalalignment=\"right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25,15))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(auc_results)\n",
    "ax.set_xticklabels(names)\n",
    "\n",
    "plt.ylabel('ROC AUC Score\\n',\n",
    "horizontalalignment=\"center\",fontstyle = \"normal\", \n",
    "fontsize = \"large\", fontfamily = \"sans-serif\")\n",
    "\n",
    "plt.xlabel('\\n Baseline Classification Algorithms\\n',\n",
    "horizontalalignment=\"center\",fontstyle = \"normal\", \n",
    "fontsize = \"large\", fontfamily = \"sans-serif\")\n",
    "\n",
    "plt.title('ROC AUC Comparison \\n',\n",
    "horizontalalignment=\"center\", fontstyle = \"normal\", \n",
    "fontsize = \"22\", fontfamily = \"sans-serif\")\n",
    "\n",
    "plt.xticks(rotation=0, horizontalalignment=\"center\")\n",
    "plt.yticks(rotation=0, horizontalalignment=\"right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_array = []\n",
    "\n",
    "for each in range(1,25):\n",
    "    knn_loop = KNeighborsClassifier(n_neighbors = each) \n",
    "    knn_loop.fit(X_train,y_train)\n",
    "    score_array.append(knn_loop.score(X_test,y_test))\n",
    "\n",
    "score_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 7))\n",
    "plt.plot(range(1,25),score_array, color = '#ec838a')\n",
    "plt.ylabel('Range\\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n",
    "plt.xlabel('Score\\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n",
    "\n",
    "plt.title('Optimal Number of K Neighbors \\n',horizontalalignment=\"center\", fontstyle = \"normal\",fontsize = \"22\", fontfamily = \"sans-serif\")\n",
    "#plt.legend(loc='top right', fontsize = \"medium\")\n",
    "\n",
    "plt.xticks(rotation=0, horizontalalignment=\"center\")\n",
    "plt.yticks(rotation=0, horizontalalignment=\"right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_array = []\n",
    "for each in range(1,100):\n",
    "    rf_loop = RandomForestClassifier(n_estimators = each, random_state = 1) \n",
    "    rf_loop.fit(X_train,y_train)\n",
    "    score_array.append(rf_loop.score(X_test,y_test))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in enumerate(score_array):\n",
    "    print(i+1,\":\",j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 7))\n",
    "plt.plot(range(1,100),score_array, color = '#ec838a')\n",
    "plt.ylabel('Range\\n',horizontalalignment=\"center\",\n",
    "fontstyle = \"normal\", fontsize = \"large\", \n",
    "fontfamily = \"sans-serif\")\n",
    "plt.xlabel('Score\\n',horizontalalignment=\"center\",\n",
    "fontstyle = \"normal\", fontsize = \"large\", \n",
    "fontfamily = \"sans-serif\")\n",
    "plt.title('Optimal Number of Trees for Random Forest Model \\n',horizontalalignment=\"center\", fontstyle = \"normal\", fontsize = \"22\", fontfamily = \"sans-serif\")\n",
    "#plt.legend(loc='top right', fontsize = \"medium\")\n",
    "plt.xticks(rotation=0, horizontalalignment=\"center\")\n",
    "plt.yticks(rotation=0, horizontalalignment=\"right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation of results\n",
    "def model_evaluation(y_test, y_pred, model_name):\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    f2 = fbeta_score(y_test, y_pred, beta = 2.0)\n",
    "\n",
    "    results = pd.DataFrame([[model_name, acc, prec, rec, f1, f2]], \n",
    "                       columns = [\"Model\", \"Accuracy\", \"Precision\", \"Recall\",\n",
    "                                 \"F1 SCore\", \"F2 Score\"])\n",
    "    results = results.sort_values([\"Precision\", \"Recall\", \"F2 Score\"], ascending = False)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression\n",
    "classifier = LogisticRegression(random_state=0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "#SVC\n",
    "\n",
    "classifier2 = SVC(kernel = 'linear', random_state = 0)\n",
    "classifier2.fit(X_train, y_train)\n",
    "y_pred2 = classifier2.predict(X_test)\n",
    "\n",
    "#knn\n",
    "\n",
    "classifier3 = KNeighborsClassifier(n_neighbors=22, metric=\"minkowski\", p=2)\n",
    "classifier3.fit(X_train, y_train)\n",
    "y_pred3 = classifier3.predict(X_test)\n",
    "\n",
    "\n",
    "#Kernel SVM\n",
    "classifier4 = SVC(kernel=\"rbf\", random_state =0)\n",
    "classifier4.fit(X_train, y_train)\n",
    "y_pred4 = classifier4.predict(X_test)\n",
    "\n",
    "\n",
    "#Naive Bayes\n",
    "classifier5 = GaussianNB()\n",
    "classifier5.fit(X_train, y_train)\n",
    "y_pred5 = classifier5.predict(X_test)\n",
    "\n",
    "#Decision tree\n",
    "classifier6 = DecisionTreeClassifier(criterion=\"entropy\", random_state=0)\n",
    "classifier6.fit(X_train, y_train)\n",
    "y_pred6 = classifier6.predict(X_test)\n",
    "\n",
    "#Random Forest\n",
    "\n",
    "classifier7 = RandomForestClassifier(n_estimators=72, criterion=\"entropy\", random_state=0)\n",
    "classifier7.fit(X_train, y_train)\n",
    "y_pred7 = classifier7.predict(X_test)\n",
    "\n",
    "#Adaboost\n",
    "classifier8 = AdaBoostClassifier()\n",
    "classifier8.fit(X_train, y_train)\n",
    "y_pred8 = classifier8.predict(X_test)\n",
    "\n",
    "#Gradient Boost\n",
    "classifier9 = GradientBoostingClassifier()\n",
    "\n",
    "\n",
    "classifier9.fit(X_train, y_train)\n",
    "y_pred9 = classifier9.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Voting Classifier\n",
    "\n",
    "classifier10 = VotingClassifier(estimators=[('gbc', GradientBoostingClassifier()), ('lr', LogisticRegression()),\n",
    "                                            ('abc', AdaBoostClassifier())], voting='soft')\n",
    "\n",
    "\n",
    "\n",
    "classifier10.fit(X_train, y_train)\n",
    "y_pred10 = classifier10.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = model_evaluation(y_test, y_pred, \"Logistic Regression\")\n",
    "svm = model_evaluation(y_test, y_pred2, \"SVM (Linear)\")\n",
    "knn = model_evaluation(y_test, y_pred3, \"K-Nearest Neighbours\")\n",
    "k_svm = model_evaluation(y_test, y_pred4, \"Kernel SVM\")\n",
    "nb = model_evaluation(y_test, y_pred5, \"Naive Bayes\")\n",
    "dt = model_evaluation(y_test, y_pred6, \"Decision Tree\")\n",
    "rf = model_evaluation(y_test, y_pred7, \"Random Forest\")\n",
    "ab = model_evaluation(y_test, y_pred8, \"Adaboost\")\n",
    "gb = model_evaluation(y_test, y_pred9, \"Gradient Boost\")\n",
    "vc = model_evaluation(y_test, y_pred10, \"Voting Classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_ =lr.append(svm).append(knn).append(k_svm).append(nb).append(dt).append(rf).append(ab).append(gb).append(vc).sort_values([\"Precision\", \n",
    "\"Recall\", \"F2 Score\"], ascending = False).reset_index().drop(columns = \"index\")\n",
    "eval_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predictions = [y_pred, y_pred2 , y_pred3, y_pred4, y_pred5, y_pred5, y_pred6, y_pred7,\n",
    "              y_pred8, y_pred9, y_pred10]\n",
    "\n",
    "for i, j in zip(predictions, eval_.Model.values):\n",
    "    plt.figure(figsize=(4,3))\n",
    "    sns.heatmap(confusion_matrix(y_test, i),\n",
    "                annot=True,fmt = \"d\",linecolor=\"k\",linewidths=3)\n",
    "    \n",
    "    plt.title(j,fontsize=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>k-Fold Cross-Validation</b>: Model evaluation is most commonly done through ‘K- fold Cross-Validation’ technique that primarily helps us to fix the variance. Variance problem occurs when we get good accuracy while running the model on a training set and a test set but then the accuracy looks different when the model is run on another test set.\n",
    "So, in order to fix the variance problem, k-fold cross-validation basically split the training set into 10 folds and train the model on 9 folds (9 subsets of the training dataset) before testing it on the test fold. This gives us the flexibility to train our model on all ten combinations of 9 folds; giving ample room to finalize the variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cross_validation(classifier_name, name):\n",
    "    accuracies = cross_val_score(estimator=classifier_name,\n",
    "                            X=X_train, y=y_train, cv =10)\n",
    "    print(name, \"accuracy: %0.2f (+/- %0.2f)\"  % (accuracies.mean(), accuracies.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold_cross_validation(classifier8, \"Adaboost\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold_cross_validation(classifier10, \"Voting classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold_cross_validation(classifier9, \"Gradient Boost classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold_cross_validation(classifier, \"Logistic regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold_cross_validation(classifier4, \"Kernel SVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "\n",
    "def ROC_curve(classifier_, name, y_pred_):\n",
    "    classifier_.fit(X_train, y_train) \n",
    "    probs = classifier_.predict_proba(X_test) \n",
    "    probs = probs[:, 1] \n",
    "    classifier_roc_auc = roc_auc_score(y_test, probs )\n",
    "    rf_fpr, rf_tpr, rf_thresholds = roc_curve(y_test, classifier_.predict_proba(X_test)[:,1])\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    label_ = name + '(area = %0.2f)' % classifier_roc_auc\n",
    "    # Plot Adaboost ROC\n",
    "    plt.plot(rf_fpr, rf_tpr, \n",
    "    label=label_)\n",
    "    # Plot Base Rate ROC\n",
    "    plt.plot([0,1], [0,1],label='Base Rate' 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.ylabel('True Positive Rate \\n',horizontalalignment=\"center\",\n",
    "    fontstyle = \"normal\", fontsize = \"medium\", \n",
    "    fontfamily = \"sans-serif\")\n",
    "\n",
    "    plt.xlabel('\\nFalse Positive Rate \\n',horizontalalignment=\"center\",\n",
    "    fontstyle = \"normal\", fontsize = \"medium\", \n",
    "    fontfamily = \"sans-serif\")\n",
    "\n",
    "    plt.title('ROC Graph \\n',horizontalalignment=\"center\", \n",
    "    fontstyle = \"normal\", fontsize = \"22\", \n",
    "    fontfamily = \"sans-serif\")\n",
    "\n",
    "    plt.legend(loc=\"lower right\", fontsize = \"medium\")\n",
    "    plt.xticks(rotation=0, horizontalalignment=\"center\")\n",
    "    plt.yticks(rotation=0, horizontalalignment=\"right\")\n",
    "    plt.show()\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "preds = [y_pred, y_pred3,  y_pred5, y_pred6, y_pred7,\n",
    "              y_pred8, y_pred9, y_pred10]\n",
    "classifiers = [classifier , classifier3, classifier5, classifier6, classifier7,\n",
    "             classifier8, classifier9, classifier10]\n",
    "model_names_ = [\"Logistic Regression\",  \"K-Nearest Neighbours\",\"Naive Bayes\",\n",
    "               \"Decision Tree\", \"Random Forest\", \"Adaboost\", \"Gradient Boost\",  \"Voting Classifier\"]\n",
    "\n",
    "for i, j, k in zip(classifiers, model_names_, predictions):\n",
    "    ROC_curve(i, j, k) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Function that will track the mean value and the standard deviation of the accuracy\n",
    "def cvDictGen(functions, scr, X_train = X, y_train = y, cv = 5):\n",
    "    cvDict = {}\n",
    "    for func in functions:\n",
    "        cvScore = cross_val_score(func, X_train, y_train, cv = cv, scoring = scr)\n",
    "        cvDict[str(func).split('(')[0]] = [cvScore.mean(), cvScore.std()]\n",
    "    \n",
    "    return cvDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvD = cvDictGen(classifiers, scr = 'roc_auc')\n",
    "cvD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boost\n",
    "feature_importances = pd.concat([pd.DataFrame(data.columns, columns = [\"features\"]),\n",
    "                                 pd.DataFrame(np.transpose(classifier9.feature_importances_), columns = [\"coef\"])],axis = 1)\n",
    "feature_importances.sort_values(by = \"coef\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ada boost classifier\n",
    "feature_importances = pd.concat([pd.DataFrame(data.columns, columns = [\"features\"]),\n",
    "                                 pd.DataFrame(np.transpose(classifier8.feature_importances_), columns = [\"coef\"])],axis = 1)\n",
    "feature_importances.sort_values(by = \"coef\", ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Randomized search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ada boost\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "adaHyperParams = {'n_estimators': [10,50,100,200,420], \"learning_rate\":  [0.001, 0.01, 0.1, 0.3]}\n",
    "gridSearchAda = RandomizedSearchCV(estimator = classifier8, param_distributions = adaHyperParams, n_iter = 5,\n",
    "                                   scoring = 'roc_auc') # other option accuracy\n",
    "gridSearchAda.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridSearchAda.best_params_, gridSearchAda.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestAdaModFitted = gridSearchAda.best_estimator_.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the score AdaBoost\n",
    "test_labels = bestAdaModFitted.predict_proba(np.array(X_test.values))[:,1]\n",
    "roc_auc_score(y_test,test_labels , average = 'macro', sample_weight = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbHyperParams = {'loss' : ['deviance', 'exponential'],\n",
    "                 'n_estimators': randint(10, 500),\n",
    "                 'max_depth': randint(1,10)}\n",
    "# Initialization\n",
    "gridSearchGB = RandomizedSearchCV(estimator = classifier9, param_distributions = gbHyperParams, n_iter = 10,\n",
    "                                   scoring = 'roc_auc')\n",
    "# Fitting the model\n",
    "gridSearchGB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridSearchGB.best_params_, gridSearchGB.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestGBModFitted = gridSearchGB.best_estimator_.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the score AdaBoost\n",
    "test_labels_GB = bestGBModFitted.predict_proba(np.array(X_test.values))[:,1]\n",
    "roc_auc_score(y_test,test_labels_GB , average = 'macro', sample_weight = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Grid SearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABC = AdaBoostClassifier()\n",
    "\n",
    "ABC_param_grid = {\"n_estimators\" :[10,50,100,200,420],\n",
    "                  \"learning_rate\":  [0.001, 0.01, 0.1, 0.3]}\n",
    "\n",
    "gsABC = GridSearchCV(ABC, param_grid = ABC_param_grid, cv = 10, scoring = \"roc_auc\", n_jobs = 6, verbose = 1)\n",
    "\n",
    "gsABC.fit(X_train,y_train)\n",
    "\n",
    "ada_best = gsABC.best_estimator_\n",
    "print(ada_best)\n",
    "print(gsABC.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestAdaModFitted2 = gsABC.best_estimator_.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = bestAdaModFitted2.predict_proba(np.array(X_test.values))[:,1]\n",
    "roc_auc_score(y_test,test_labels , average = 'macro', sample_weight = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://towardsdatascience.com/predict-customer-churn-in-python-e8cd6d3aaa7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_param_grid = {'loss' : ['deviance'],\n",
    "                 'n_estimators': [10,100,200,300],\n",
    "                 'max_depth': [1,2,4,6,8]}\n",
    "\n",
    "gsGB = GridSearchCV(classifier9, param_grid = gb_param_grid, cv = 10, scoring = \"roc_auc\", n_jobs = 6, verbose = 1)\n",
    "\n",
    "gsGB.fit(X_train,y_train)\n",
    "\n",
    "gb_best = gsGB.best_estimator_\n",
    "print(gb_best)\n",
    "print(gsGB.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestGBModFitted2 = gsGB.best_estimator_.fit(X_train, y_train)\n",
    "\n",
    "test_labels_gb2 = bestGBModFitted2.predict_proba(np.array(X_test.values))[:,1]\n",
    "roc_auc_score(y_test,test_labels_gb2 , average = 'macro', sample_weight = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
